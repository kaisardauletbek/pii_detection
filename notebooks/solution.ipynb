{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kd/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import transformers\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertConfig, BertForTokenClassification\n",
    "from torch import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "753"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test.tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json('train.json')\n",
    "test = pd.read_json('test.json')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>full_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>trailing_whitespace</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>Design Thinking for innovation reflexion-Avril...</td>\n",
       "      <td>[Design, Thinking, for, innovation, reflexion,...</td>\n",
       "      <td>[True, True, True, True, False, False, True, F...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...</td>\n",
       "      <td>[Diego, Estrada, \\n\\n, Design, Thinking, Assig...</td>\n",
       "      <td>[True, False, False, True, True, False, False,...</td>\n",
       "      <td>[B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...</td>\n",
       "      <td>[Reporting, process, \\n\\n, by, Gilberto, Gambo...</td>\n",
       "      <td>[True, False, False, True, True, False, False,...</td>\n",
       "      <td>[O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>Design Thinking for Innovation\\n\\nSindy Samaca...</td>\n",
       "      <td>[Design, Thinking, for, Innovation, \\n\\n, Sind...</td>\n",
       "      <td>[True, True, True, False, False, True, False, ...</td>\n",
       "      <td>[O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>Assignment:  Visualization Reflection  Submitt...</td>\n",
       "      <td>[Assignment, :,   , Visualization,  , Reflecti...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, B-NAME_ST...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6802</th>\n",
       "      <td>22678</td>\n",
       "      <td>EXAMPLE – JOURNEY MAP\\n\\nTHE CHALLENGE    My w...</td>\n",
       "      <td>[EXAMPLE, –, JOURNEY, MAP, \\n\\n, THE, CHALLENG...</td>\n",
       "      <td>[True, True, True, False, False, True, True, F...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6803</th>\n",
       "      <td>22679</td>\n",
       "      <td>Why Mind Mapping?\\n\\nMind maps are graphical r...</td>\n",
       "      <td>[Why, Mind, Mapping, ?, \\n\\n, Mind, maps, are,...</td>\n",
       "      <td>[True, True, False, False, False, True, True, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6804</th>\n",
       "      <td>22681</td>\n",
       "      <td>Challenge\\n\\nSo, a few months back, I had chos...</td>\n",
       "      <td>[Challenge, \\n\\n, So, ,, a, few, months, back,...</td>\n",
       "      <td>[False, False, False, True, True, True, True, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805</th>\n",
       "      <td>22684</td>\n",
       "      <td>Brainstorming\\n\\nChallenge &amp; Selection\\n\\nBrai...</td>\n",
       "      <td>[Brainstorming, \\n\\n, Challenge, &amp;, Selection,...</td>\n",
       "      <td>[False, False, True, True, False, False, True,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6806</th>\n",
       "      <td>22687</td>\n",
       "      <td>Mind Mapping\\n\\nChallenge\\n\\nMy consulting tea...</td>\n",
       "      <td>[Mind, Mapping, \\n\\n, Challenge, \\n\\n, My, con...</td>\n",
       "      <td>[True, False, False, False, False, True, True,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6807 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      document                                          full_text  \\\n",
       "0            7  Design Thinking for innovation reflexion-Avril...   \n",
       "1           10  Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...   \n",
       "2           16  Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...   \n",
       "3           20  Design Thinking for Innovation\\n\\nSindy Samaca...   \n",
       "4           56  Assignment:  Visualization Reflection  Submitt...   \n",
       "...        ...                                                ...   \n",
       "6802     22678  EXAMPLE – JOURNEY MAP\\n\\nTHE CHALLENGE    My w...   \n",
       "6803     22679  Why Mind Mapping?\\n\\nMind maps are graphical r...   \n",
       "6804     22681  Challenge\\n\\nSo, a few months back, I had chos...   \n",
       "6805     22684  Brainstorming\\n\\nChallenge & Selection\\n\\nBrai...   \n",
       "6806     22687  Mind Mapping\\n\\nChallenge\\n\\nMy consulting tea...   \n",
       "\n",
       "                                                 tokens  \\\n",
       "0     [Design, Thinking, for, innovation, reflexion,...   \n",
       "1     [Diego, Estrada, \\n\\n, Design, Thinking, Assig...   \n",
       "2     [Reporting, process, \\n\\n, by, Gilberto, Gambo...   \n",
       "3     [Design, Thinking, for, Innovation, \\n\\n, Sind...   \n",
       "4     [Assignment, :,   , Visualization,  , Reflecti...   \n",
       "...                                                 ...   \n",
       "6802  [EXAMPLE, –, JOURNEY, MAP, \\n\\n, THE, CHALLENG...   \n",
       "6803  [Why, Mind, Mapping, ?, \\n\\n, Mind, maps, are,...   \n",
       "6804  [Challenge, \\n\\n, So, ,, a, few, months, back,...   \n",
       "6805  [Brainstorming, \\n\\n, Challenge, &, Selection,...   \n",
       "6806  [Mind, Mapping, \\n\\n, Challenge, \\n\\n, My, con...   \n",
       "\n",
       "                                    trailing_whitespace  \\\n",
       "0     [True, True, True, True, False, False, True, F...   \n",
       "1     [True, False, False, True, True, False, False,...   \n",
       "2     [True, False, False, True, True, False, False,...   \n",
       "3     [True, True, True, False, False, True, False, ...   \n",
       "4     [False, False, False, False, False, False, Fal...   \n",
       "...                                                 ...   \n",
       "6802  [True, True, True, False, False, True, True, F...   \n",
       "6803  [True, True, False, False, False, True, True, ...   \n",
       "6804  [False, False, False, True, True, True, True, ...   \n",
       "6805  [False, False, True, True, False, False, True,...   \n",
       "6806  [True, False, False, False, False, True, True,...   \n",
       "\n",
       "                                                 labels  \n",
       "0     [O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...  \n",
       "1     [B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...  \n",
       "2     [O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O...  \n",
       "3     [O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...  \n",
       "4     [O, O, O, O, O, O, O, O, O, O, O, O, B-NAME_ST...  \n",
       "...                                                 ...  \n",
       "6802  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "6803  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "6804  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "6805  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "6806  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "\n",
       "[6807 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128#max([len(sentence) for sentence in sentences]) #3298\n",
    "maxlen = MAX_LEN\n",
    "TRAIN_BATCH_SIZE = 4 \n",
    "VALID_BATCH_SIZE = 2\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 1e-05\n",
    "MAX_GRAD_NORM = 10\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_preserve_labels(sentence, text_labels, tokenizer):\n",
    "    \"\"\"\n",
    "    Word piece tokenization makes it difficult to match word labels\n",
    "    back up with individual word pieces. This function tokenizes each\n",
    "    word one at a time so that it is easier to preserve the correct\n",
    "    label for each subword. It is, of course, a bit slower in processing\n",
    "    time, but it will help our model achieve higher accuracy.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenized_sentence = []\n",
    "    labels = []\n",
    "\n",
    "#     sentence = sentence.strip()\n",
    "\n",
    "#     for word, label in zip(sentence.split(), text_labels.split(\",\")):\n",
    "    for word, label in zip(sentence, text_labels):\n",
    "\n",
    "        # Tokenize the word and count # of subwords the word is broken into\n",
    "        tokenized_word = tokenizer.tokenize(word)\n",
    "        n_subwords = len(tokenized_word)\n",
    "\n",
    "        # Add the tokenized word to the final tokenized word list\n",
    "        tokenized_sentence.extend(tokenized_word)\n",
    "\n",
    "        # Add the same label to the new list of labels `n_subwords` times\n",
    "        labels.extend([label] * n_subwords)\n",
    "\n",
    "    return tokenized_sentence, labels\n",
    "\n",
    "def augment_data_with_tokenizer(df):\n",
    "    tokenized_sentences = []\n",
    "    preserved_labels = []\n",
    "    for i in range(len(df)):\n",
    "        tokenized_sentence, preserved_label = tokenize_and_preserve_labels(df.tokens[i], df.labels[i], tokenizer)\n",
    "        tokenized_sentences.append(tokenized_sentence)\n",
    "        preserved_labels.append(preserved_label)\n",
    "    \n",
    "    df_aug = pd.DataFrame()\n",
    "    df_aug['tokenized_sentences'] = tokenized_sentences\n",
    "    df_aug['preserved_labels'] = preserved_labels\n",
    "    return df_aug\n",
    "\n",
    "def batchify_augmented_data(df_aug):\n",
    "    \n",
    "    df_aug_batched = pd.DataFrame()\n",
    "    tokenized_sentences_batched = []\n",
    "    preserved_labels_batched = []\n",
    "\n",
    "    for i in range(len(df_aug)):\n",
    "        tokens = df_aug['tokenized_sentences'][i]\n",
    "        labels = df_aug['preserved_labels'][i]\n",
    "        tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"] # add special tokens\n",
    "        labels.insert(0, \"O\") # add outside label for [CLS] token\n",
    "        labels.insert(-1, \"O\") # add outside label for [SEP] token\n",
    "\n",
    "        prev_j = 0\n",
    "        if len(tokens) % maxlen == 0:\n",
    "            upper_iter = len(tokens)\n",
    "        else:\n",
    "            upper_iter = (len(tokens) // maxlen + 2) * maxlen\n",
    "        for j in range(maxlen, upper_iter, maxlen):\n",
    "            if len(tokens[prev_j:j]) == maxlen:\n",
    "                tokenized_sentences_batched.append(tokens[prev_j:j])\n",
    "                preserved_labels_batched.append(labels[prev_j:j])\n",
    "            else:\n",
    "                tokenized_sentences_batched.append(tokens[prev_j:j] + ['[PAD]'for _ in range(maxlen - len(tokens[prev_j:j]))])\n",
    "                preserved_labels_batched.append(labels[prev_j:j] + [\"O\" for _ in range(maxlen - len(labels[prev_j:j]))])\n",
    "\n",
    "            prev_j = j\n",
    "\n",
    "    df_aug_batched['tokenized_sentences'] = tokenized_sentences_batched\n",
    "    df_aug_batched['preserved_labels'] = preserved_labels_batched\n",
    "    return df_aug_batched\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>full_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>trailing_whitespace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>Design Thinking for innovation reflexion-Avril...</td>\n",
       "      <td>[Design, Thinking, for, innovation, reflexion,...</td>\n",
       "      <td>[True, True, True, True, False, False, True, F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...</td>\n",
       "      <td>[Diego, Estrada, \\n\\n, Design, Thinking, Assig...</td>\n",
       "      <td>[True, False, False, True, True, False, False,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...</td>\n",
       "      <td>[Reporting, process, \\n\\n, by, Gilberto, Gambo...</td>\n",
       "      <td>[True, False, False, True, True, False, False,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>Design Thinking for Innovation\\n\\nSindy Samaca...</td>\n",
       "      <td>[Design, Thinking, for, Innovation, \\n\\n, Sind...</td>\n",
       "      <td>[True, True, True, False, False, True, False, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>Assignment:  Visualization Reflection  Submitt...</td>\n",
       "      <td>[Assignment, :,   , Visualization,  , Reflecti...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>86</td>\n",
       "      <td>Cheese Startup - Learning Launch ​by Eladio Am...</td>\n",
       "      <td>[Cheese, Startup, -, Learning, Launch, ​by, El...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Fal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>93</td>\n",
       "      <td>Silvia Villalobos\\n\\nChallenge:\\n\\nThere is a ...</td>\n",
       "      <td>[Silvia, Villalobos, \\n\\n, Challenge, :, \\n\\n,...</td>\n",
       "      <td>[True, False, False, False, False, False, True...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>104</td>\n",
       "      <td>Storytelling  The Path to Innovation\\n\\nDr Sak...</td>\n",
       "      <td>[Storytelling,  , The, Path, to, Innovation, \\...</td>\n",
       "      <td>[True, False, True, True, True, False, False, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>112</td>\n",
       "      <td>Reflection – Learning Launch\\n\\nFrancisco Ferr...</td>\n",
       "      <td>[Reflection, –, Learning, Launch, \\n\\n, Franci...</td>\n",
       "      <td>[True, True, True, False, False, True, False, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>123</td>\n",
       "      <td>Gandhi Institute of Technology and Management ...</td>\n",
       "      <td>[Gandhi, Institute, of, Technology, and, Manag...</td>\n",
       "      <td>[True, True, True, True, True, True, False, Tr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document                                          full_text  \\\n",
       "0         7  Design Thinking for innovation reflexion-Avril...   \n",
       "1        10  Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...   \n",
       "2        16  Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...   \n",
       "3        20  Design Thinking for Innovation\\n\\nSindy Samaca...   \n",
       "4        56  Assignment:  Visualization Reflection  Submitt...   \n",
       "5        86  Cheese Startup - Learning Launch ​by Eladio Am...   \n",
       "6        93  Silvia Villalobos\\n\\nChallenge:\\n\\nThere is a ...   \n",
       "7       104  Storytelling  The Path to Innovation\\n\\nDr Sak...   \n",
       "8       112  Reflection – Learning Launch\\n\\nFrancisco Ferr...   \n",
       "9       123  Gandhi Institute of Technology and Management ...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Design, Thinking, for, innovation, reflexion,...   \n",
       "1  [Diego, Estrada, \\n\\n, Design, Thinking, Assig...   \n",
       "2  [Reporting, process, \\n\\n, by, Gilberto, Gambo...   \n",
       "3  [Design, Thinking, for, Innovation, \\n\\n, Sind...   \n",
       "4  [Assignment, :,   , Visualization,  , Reflecti...   \n",
       "5  [Cheese, Startup, -, Learning, Launch, ​by, El...   \n",
       "6  [Silvia, Villalobos, \\n\\n, Challenge, :, \\n\\n,...   \n",
       "7  [Storytelling,  , The, Path, to, Innovation, \\...   \n",
       "8  [Reflection, –, Learning, Launch, \\n\\n, Franci...   \n",
       "9  [Gandhi, Institute, of, Technology, and, Manag...   \n",
       "\n",
       "                                 trailing_whitespace  \n",
       "0  [True, True, True, True, False, False, True, F...  \n",
       "1  [True, False, False, True, True, False, False,...  \n",
       "2  [True, False, False, True, True, False, False,...  \n",
       "3  [True, True, True, False, False, True, False, ...  \n",
       "4  [False, False, False, False, False, False, Fal...  \n",
       "5  [True, True, True, True, True, True, True, Fal...  \n",
       "6  [True, False, False, False, False, False, True...  \n",
       "7  [True, False, True, True, True, False, False, ...  \n",
       "8  [True, True, True, False, False, True, False, ...  \n",
       "9  [True, True, True, True, True, True, False, Tr...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_preserve_labels_test(sentence, tokenizer):\n",
    "    \"\"\"\n",
    "    Word piece tokenization makes it difficult to match word labels\n",
    "    back up with individual word pieces. This function tokenizes each\n",
    "    word one at a time so that it is easier to preserve the correct\n",
    "    label for each subword. It is, of course, a bit slower in processing\n",
    "    time, but it will help our model achieve higher accuracy.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenized_sentence = []\n",
    "#     labels = []\n",
    "\n",
    "#     sentence = sentence.strip()\n",
    "\n",
    "#     for word, label in zip(sentence.split(), text_labels.split(\",\")):\n",
    "    for word in sentence:\n",
    "\n",
    "        # Tokenize the word and count # of subwords the word is broken into\n",
    "        tokenized_word = tokenizer.tokenize(word)\n",
    "        n_subwords = len(tokenized_word)\n",
    "\n",
    "        # Add the tokenized word to the final tokenized word list\n",
    "        tokenized_sentence.extend(tokenized_word)\n",
    "\n",
    "        # Add the same label to the new list of labels `n_subwords` times\n",
    "#         labels.extend([label] * n_subwords)\n",
    "\n",
    "    return tokenized_sentence #, labels\n",
    "\n",
    "def augment_data_with_tokenizer_test(df):\n",
    "    doc_ids = []\n",
    "    tokenized_sentences = []\n",
    "#     preserved_labels = []\n",
    "    for i in range(len(df)):\n",
    "        doc_ids.append(df.document[i])\n",
    "        tokenized_sentence = tokenize_and_preserve_labels_test(df.tokens[i], tokenizer)\n",
    "        tokenized_sentences.append(tokenized_sentence)\n",
    "#         preserved_labels.append(preserved_label)\n",
    "    \n",
    "    df_aug = pd.DataFrame()\n",
    "    df_aug['tokenized_sentences'] = tokenized_sentences\n",
    "    df_aug['document'] = doc_ids\n",
    "#     df_aug['preserved_labels'] = preserved_labels\n",
    "    return df_aug\n",
    "\n",
    "def batchify_augmented_data_test(df_aug):\n",
    "    df_aug_batched = pd.DataFrame()\n",
    "    doc_ids_batched = []\n",
    "    tokenized_sentences_batched = []\n",
    "#     preserved_labels_batched = []\n",
    "\n",
    "    for i in range(len(df_aug)):\n",
    "        tokens = df_aug['tokenized_sentences'][i]\n",
    "        tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"] # add special tokens\n",
    "        prev_j = 0\n",
    "        if len(tokens) % maxlen == 0:\n",
    "            upper_iter = len(tokens)\n",
    "        else:\n",
    "            upper_iter = (len(tokens) // maxlen + 2) * maxlen\n",
    "        for j in range(maxlen, upper_iter, maxlen):\n",
    "            if len(tokens[prev_j:j]) == maxlen:\n",
    "                tokenized_sentences_batched.append(tokens[prev_j:j])\n",
    "            else:\n",
    "                tokenized_sentences_batched.append(tokens[prev_j:j] + ['[PAD]'for _ in range(maxlen - len(tokens[prev_j:j]))])\n",
    "\n",
    "            doc_ids_batched.append(df_aug['document'][i])\n",
    "\n",
    "            prev_j = j\n",
    "\n",
    "    df_aug_batched['tokenized_sentences'] = tokenized_sentences_batched\n",
    "    df_aug_batched['document'] = doc_ids_batched\n",
    "    return df_aug_batched\n",
    "    \n",
    "\n",
    "def reverse_tokenization(tokenized_sentence, preserved_label):\n",
    "    \"\"\"\n",
    "    This function reverses the tokenization process. It takes in a\n",
    "    tokenized sentence and a list of labels and returns a list of\n",
    "    labels that corresponds to the original sentence.\n",
    "    \"\"\"\n",
    "\n",
    "    original_sentence = []\n",
    "    original_labels = []\n",
    "\n",
    "    for token, label in zip(tokenized_sentence, preserved_label):\n",
    "        # delete special tokens added during tokenization\n",
    "        if token in [\"[CLS]\", \"[SEP]\"]:\n",
    "            continue\n",
    "\n",
    "        # If the token is part of a word piece, then just add the\n",
    "        # label to the original labels list. Otherwise, add both\n",
    "        # the token and the label to their respective lists.\n",
    "        if token.startswith(\"##\"):\n",
    "            original_labels.append(label)\n",
    "        else:\n",
    "            original_sentence.append(token)\n",
    "            original_labels.append(label)\n",
    "\n",
    "    return original_sentence, original_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentences = []\n",
    "preserved_labels = []\n",
    "for i in range(len(train)):\n",
    "    tokenized_sentence, preserved_label = tokenize_and_preserve_labels(train.tokens[i], train.labels[i], tokenizer)\n",
    "    tokenized_sentences.append(tokenized_sentence)\n",
    "    preserved_labels.append(preserved_label)\n",
    "    \n",
    "train_aug = pd.DataFrame()\n",
    "train_aug['tokenized_sentences'] = tokenized_sentences\n",
    "train_aug['preserved_labels'] = preserved_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aug_batched = pd.DataFrame()\n",
    "tokenized_sentences_batched = []\n",
    "preserved_labels_batched = []\n",
    "\n",
    "for i in range(len(train_aug)):\n",
    "    tokens = train_aug['tokenized_sentences'][i]\n",
    "    labels = train_aug['preserved_labels'][i]\n",
    "    tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"] # add special tokens\n",
    "    labels.insert(0, \"O\") # add outside label for [CLS] token\n",
    "    labels.insert(-1, \"O\") # add outside label for [SEP] token\n",
    "    \n",
    "    prev_j = 0\n",
    "    if len(tokens) % maxlen == 0:\n",
    "        upper_iter = len(tokens)\n",
    "    else:\n",
    "        upper_iter = (len(tokens) // maxlen + 2) * maxlen\n",
    "    for j in range(maxlen, upper_iter, maxlen):\n",
    "        if len(tokens[prev_j:j]) == maxlen:\n",
    "            tokenized_sentences_batched.append(tokens[prev_j:j])\n",
    "            preserved_labels_batched.append(labels[prev_j:j])\n",
    "        else:\n",
    "            tokenized_sentences_batched.append(tokens[prev_j:j] + ['[PAD]'for _ in range(maxlen - len(tokens[prev_j:j]))])\n",
    "            preserved_labels_batched.append(labels[prev_j:j] + [\"O\" for _ in range(maxlen - len(labels[prev_j:j]))])\n",
    "\n",
    "        prev_j = j\n",
    "\n",
    "train_aug_batched['tokenized_sentences'] = tokenized_sentences_batched\n",
    "train_aug_batched['preserved_labels'] = preserved_labels_batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = train.tokens\n",
    "tags = train.labels\n",
    "\n",
    "# Vocabulary Building\n",
    "# word_to_ix = {'<PAD>':0}\n",
    "word_to_ix = {}\n",
    "for sentence in sentences:\n",
    "    for word in sentence:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "            \n",
    "# tag_to_ix = {'<PAD>':0}\n",
    "tag_to_ix = {}\n",
    "for labels in tags:\n",
    "    for tag in labels:\n",
    "        if tag not in tag_to_ix:\n",
    "            tag_to_ix[tag] = len(tag_to_ix)\n",
    "            \n",
    "ix_to_tag = dict((v,k) for k,v in tag_to_ix.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # step 1: tokenize (and adapt corresponding labels)\n",
    "#         sentence = self.data.sentence[index]  \n",
    "        sentence = self.data.tokenized_sentences[index]  \n",
    "#         word_labels = self.data.word_labels[index]  \n",
    "        word_labels = self.data.preserved_labels[index]  \n",
    "#         tokenized_sentence, labels = tokenize_and_preserve_labels(sentence, word_labels, self.tokenizer)\n",
    "        tokenized_sentence, labels = sentence, word_labels\n",
    "        \n",
    "        # step 2: add special tokens (and corresponding labels)\n",
    "#         tokenized_sentence = [\"[CLS]\"] + tokenized_sentence + [\"[SEP]\"] # add special tokens\n",
    "#         labels.insert(0, \"O\") # add outside label for [CLS] token\n",
    "#         labels.insert(-1, \"O\") # add outside label for [SEP] token\n",
    "\n",
    "        # step 3: truncating/padding\n",
    "        maxlen = self.max_len\n",
    "#         tokenized_sentences = []\n",
    "#         if (len(tokenized_sentence) > maxlen):\n",
    "#           # truncate\n",
    "#             for i in range(0, len(tokenized_sentence)//maxlen+1, maxlen):\n",
    "#                 if i == max_len\n",
    "#                 tokenized_sentences.append(tokenized_sentence[:])\n",
    "#                 labels = labels[:maxlen]\n",
    "#         else:\n",
    "#           # pad\n",
    "#             tokenized_sentence = tokenized_sentence + ['[PAD]'for _ in range(maxlen - len(tokenized_sentence))]\n",
    "#             labels = labels + [\"O\" for _ in range(maxlen - len(labels))]\n",
    "\n",
    "        # step 4: obtain the attention mask\n",
    "        attn_mask = [1 if tok != '[PAD]' else 0 for tok in tokenized_sentence]\n",
    "        \n",
    "        # step 5: convert tokens to input ids\n",
    "        ids = self.tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
    "\n",
    "#         label_ids = [label2id[label] for label in labels]\n",
    "        label_ids = [tag_to_ix[label] for label in labels]\n",
    "\n",
    "        # the following line is deprecated\n",
    "        #label_ids = [label if label != 0 else -100 for label in label_ids]\n",
    "        \n",
    "        return {\n",
    "              'ids': torch.tensor(ids, dtype=torch.long),\n",
    "              'mask': torch.tensor(attn_mask, dtype=torch.long),\n",
    "              #'token_type_ids': torch.tensor(token_ids, dtype=torch.long),\n",
    "              'targets': torch.tensor(label_ids, dtype=torch.long)\n",
    "        } \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (41024, 2)\n",
      "TRAIN Dataset: (32819, 2)\n",
      "TEST Dataset: (8205, 2)\n"
     ]
    }
   ],
   "source": [
    "train_size = 0.8\n",
    "train_dataset = train_aug_batched.sample(frac=train_size,random_state=200)\n",
    "test_dataset = train_aug_batched.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(train_aug_batched.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=13, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = BertForTokenClassification.from_pretrained('bert-base-uncased', \n",
    "#                                                    num_labels=len(ix_to_tag),\n",
    "#                                                    id2label=ix_to_tag,\n",
    "#                                                    label2id=tag_to_ix)\n",
    "\n",
    "model = torch.load(\"bert_tuned.pt\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.4799e-05, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = training_set[0][\"ids\"].unsqueeze(0)\n",
    "mask = training_set[0][\"mask\"].unsqueeze(0)\n",
    "targets = training_set[0][\"targets\"].unsqueeze(0)\n",
    "ids = ids.to(device)\n",
    "mask = mask.to(device)\n",
    "targets = targets.to(device)\n",
    "outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "initial_loss = outputs[0]\n",
    "initial_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
    "def train(epoch):\n",
    "    tr_loss, tr_accuracy = 0, 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    tr_preds, tr_labels = [], []\n",
    "    # put model in training mode\n",
    "    model.train()\n",
    "    \n",
    "    for idx, batch in enumerate(training_loader):\n",
    "        \n",
    "        ids = batch['ids'].to(device, dtype = torch.long)\n",
    "        mask = batch['mask'].to(device, dtype = torch.long)\n",
    "        targets = batch['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "        loss, tr_logits = outputs.loss, outputs.logits\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples += targets.size(0)\n",
    "        \n",
    "        if idx % 100==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            print(f\"Training loss per 100 training steps: {loss_step}\")\n",
    "           \n",
    "        # compute training accuracy\n",
    "        flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
    "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "        # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
    "        active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
    "        targets = torch.masked_select(flattened_targets, active_accuracy)\n",
    "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "        \n",
    "        tr_preds.extend(predictions)\n",
    "        tr_labels.extend(targets)\n",
    "        \n",
    "        tmp_tr_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
    "        tr_accuracy += tmp_tr_accuracy\n",
    "    \n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
    "        )\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = tr_loss / nb_tr_steps\n",
    "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
    "    print(f\"Training loss epoch: {epoch_loss}\")\n",
    "    print(f\"Training accuracy epoch: {tr_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1\n",
      "Training loss per 100 training steps: 2.451850652694702\n",
      "Training loss per 100 training steps: 0.23944752448524284\n",
      "Training loss per 100 training steps: 0.129338664613173\n",
      "Training loss per 100 training steps: 0.09043200793861723\n",
      "Training loss per 100 training steps: 0.07079018756138751\n",
      "Training loss per 100 training steps: 0.05973231376677625\n",
      "Training loss per 100 training steps: 0.05161113163844501\n",
      "Training loss per 100 training steps: 0.04618960790423817\n",
      "Training loss per 100 training steps: 0.04128701465606071\n",
      "Training loss per 100 training steps: 0.037359446822071284\n",
      "Training loss per 100 training steps: 0.034697882481443634\n",
      "Training loss per 100 training steps: 0.032183945825666894\n",
      "Training loss per 100 training steps: 0.02970722712935813\n",
      "Training loss per 100 training steps: 0.027890167407208996\n",
      "Training loss per 100 training steps: 0.026503496906297316\n",
      "Training loss per 100 training steps: 0.025148013693882063\n",
      "Training loss per 100 training steps: 0.02384496551111886\n",
      "Training loss per 100 training steps: 0.02276217638988399\n",
      "Training loss per 100 training steps: 0.021717417233526992\n",
      "Training loss per 100 training steps: 0.020697105096859847\n",
      "Training loss per 100 training steps: 0.02007183395903269\n",
      "Training loss per 100 training steps: 0.01963020647417839\n",
      "Training loss per 100 training steps: 0.018854215937360457\n",
      "Training loss per 100 training steps: 0.01825922504843776\n",
      "Training loss per 100 training steps: 0.017940372037599003\n",
      "Training loss per 100 training steps: 0.01749261087058244\n",
      "Training loss per 100 training steps: 0.01692153955702353\n",
      "Training loss per 100 training steps: 0.016459150741130916\n",
      "Training loss per 100 training steps: 0.016030507975052864\n",
      "Training loss per 100 training steps: 0.015561822928697408\n",
      "Training loss per 100 training steps: 0.015139492011565581\n",
      "Training loss per 100 training steps: 0.014738054652886795\n",
      "Training loss per 100 training steps: 0.014426640224213468\n",
      "Training loss per 100 training steps: 0.014107994816363125\n",
      "Training loss per 100 training steps: 0.013821222490457294\n",
      "Training loss per 100 training steps: 0.01347910080455077\n",
      "Training loss per 100 training steps: 0.013186001453985397\n",
      "Training loss per 100 training steps: 0.012860142991459142\n",
      "Training loss per 100 training steps: 0.01266540395162498\n",
      "Training loss per 100 training steps: 0.012404227428233095\n",
      "Training loss per 100 training steps: 0.012163958254149242\n",
      "Training loss per 100 training steps: 0.011997456505702877\n",
      "Training loss per 100 training steps: 0.011800480837269978\n",
      "Training loss per 100 training steps: 0.011551203929378894\n",
      "Training loss per 100 training steps: 0.011344167417628523\n",
      "Training loss per 100 training steps: 0.011117480557914556\n",
      "Training loss per 100 training steps: 0.010941073215532721\n",
      "Training loss per 100 training steps: 0.01079998174862603\n",
      "Training loss per 100 training steps: 0.010674447808624322\n",
      "Training loss per 100 training steps: 0.010479362888370324\n",
      "Training loss per 100 training steps: 0.010362435223370964\n",
      "Training loss per 100 training steps: 0.010197269937511319\n",
      "Training loss per 100 training steps: 0.010040998874267583\n",
      "Training loss per 100 training steps: 0.009906400078974151\n",
      "Training loss per 100 training steps: 0.00976442409731951\n",
      "Training loss per 100 training steps: 0.00963111461559901\n",
      "Training loss per 100 training steps: 0.009487385544731747\n",
      "Training loss per 100 training steps: 0.009349495327850793\n",
      "Training loss per 100 training steps: 0.009217651444611445\n",
      "Training loss per 100 training steps: 0.00908108911097348\n",
      "Training loss per 100 training steps: 0.008956622164841999\n",
      "Training loss per 100 training steps: 0.00882656564006947\n",
      "Training loss per 100 training steps: 0.008741715769864425\n",
      "Training loss per 100 training steps: 0.00862326474514635\n",
      "Training loss per 100 training steps: 0.008503689869050672\n",
      "Training loss per 100 training steps: 0.008404686258636057\n",
      "Training loss per 100 training steps: 0.008309728305899957\n",
      "Training loss per 100 training steps: 0.008225569936480532\n",
      "Training loss per 100 training steps: 0.008126013348794798\n",
      "Training loss per 100 training steps: 0.008022378526425105\n",
      "Training loss per 100 training steps: 0.007964004743010315\n",
      "Training loss per 100 training steps: 0.007885722109644458\n",
      "Training loss per 100 training steps: 0.007792857745086277\n",
      "Training loss per 100 training steps: 0.00776006883723625\n",
      "Training loss per 100 training steps: 0.007698201759458552\n",
      "Training loss per 100 training steps: 0.007612734687781826\n",
      "Training loss per 100 training steps: 0.007539912392380058\n",
      "Training loss per 100 training steps: 0.007461854779283952\n",
      "Training loss per 100 training steps: 0.007374865804448573\n",
      "Training loss per 100 training steps: 0.007342037816516065\n",
      "Training loss per 100 training steps: 0.00728674202101539\n",
      "Training loss per 100 training steps: 0.007215239044608576\n",
      "Training loss per 100 training steps: 0.007154302732814008\n",
      "Training loss epoch: 0.007150988308976034\n",
      "Training accuracy epoch: 0.9987256521175223\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Training epoch: {epoch + 1}\")\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, testing_loader):\n",
    "    # put model in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_examples, nb_eval_steps = 0, 0\n",
    "    eval_preds, eval_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(testing_loader):\n",
    "            \n",
    "            ids = batch['ids'].to(device, dtype = torch.long)\n",
    "            mask = batch['mask'].to(device, dtype = torch.long)\n",
    "            targets = batch['targets'].to(device, dtype = torch.long)\n",
    "            \n",
    "            outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "            loss, eval_logits = outputs.loss, outputs.logits\n",
    "            \n",
    "            eval_loss += loss.item()\n",
    "\n",
    "            nb_eval_steps += 1\n",
    "            nb_eval_examples += targets.size(0)\n",
    "        \n",
    "            if idx % 100==0:\n",
    "                loss_step = eval_loss/nb_eval_steps\n",
    "                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n",
    "              \n",
    "            # compute evaluation accuracy\n",
    "            flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
    "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "            # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
    "            active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
    "            targets = torch.masked_select(flattened_targets, active_accuracy)\n",
    "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "            \n",
    "            eval_labels.extend(targets)\n",
    "            eval_preds.extend(predictions)\n",
    "            \n",
    "            tmp_eval_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "    \n",
    "    #print(eval_labels)\n",
    "    #print(eval_preds)\n",
    "\n",
    "    labels = [ix_to_tag[id.item()] for id in eval_labels]\n",
    "    predictions = [ix_to_tag[id.item()] for id in eval_preds]\n",
    "\n",
    "    #print(labels)\n",
    "    #print(predictions)\n",
    "    \n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
    "    print(f\"Validation Loss: {eval_loss}\")\n",
    "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
    "\n",
    "    return labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per 100 evaluation steps: 4.337540303822607e-05\n",
      "Validation loss per 100 evaluation steps: 0.0005400009265418468\n",
      "Validation loss per 100 evaluation steps: 0.0012391629308550179\n",
      "Validation loss per 100 evaluation steps: 0.0013622688544588086\n",
      "Validation loss per 100 evaluation steps: 0.0016894232468073374\n",
      "Validation loss per 100 evaluation steps: 0.0015076147722932669\n",
      "Validation loss per 100 evaluation steps: 0.0028990827613809365\n",
      "Validation loss per 100 evaluation steps: 0.002884719690884073\n",
      "Validation loss per 100 evaluation steps: 0.002855649315125866\n",
      "Validation loss per 100 evaluation steps: 0.0030650649638324845\n",
      "Validation loss per 100 evaluation steps: 0.0031567108345551607\n",
      "Validation loss per 100 evaluation steps: 0.0034321594755636863\n",
      "Validation loss per 100 evaluation steps: 0.0033397491947732695\n",
      "Validation loss per 100 evaluation steps: 0.0033331800240040885\n",
      "Validation loss per 100 evaluation steps: 0.0032000785024714636\n",
      "Validation loss per 100 evaluation steps: 0.0032292024367224447\n",
      "Validation loss per 100 evaluation steps: 0.0031069937202148575\n",
      "Validation loss per 100 evaluation steps: 0.003049853687950515\n",
      "Validation loss per 100 evaluation steps: 0.0031106177616339347\n",
      "Validation loss per 100 evaluation steps: 0.0030372239369272865\n",
      "Validation loss per 100 evaluation steps: 0.0032485932594596804\n",
      "Validation loss per 100 evaluation steps: 0.0031605973362985474\n",
      "Validation loss per 100 evaluation steps: 0.003041329381923903\n",
      "Validation loss per 100 evaluation steps: 0.0029701522672787185\n",
      "Validation loss per 100 evaluation steps: 0.002939379020820891\n",
      "Validation loss per 100 evaluation steps: 0.002878862685111726\n",
      "Validation loss per 100 evaluation steps: 0.0028679194793043068\n",
      "Validation loss per 100 evaluation steps: 0.002796493425546272\n",
      "Validation loss per 100 evaluation steps: 0.002731258561111513\n",
      "Validation loss per 100 evaluation steps: 0.0028521393299119355\n",
      "Validation loss per 100 evaluation steps: 0.002792241971613793\n",
      "Validation loss per 100 evaluation steps: 0.0027414908998400172\n",
      "Validation loss per 100 evaluation steps: 0.0026739502599960586\n",
      "Validation loss per 100 evaluation steps: 0.002628800625377206\n",
      "Validation loss per 100 evaluation steps: 0.002594996383785493\n",
      "Validation loss per 100 evaluation steps: 0.0025449982191664035\n",
      "Validation loss per 100 evaluation steps: 0.002484963330630655\n",
      "Validation loss per 100 evaluation steps: 0.0024872632774077287\n",
      "Validation loss per 100 evaluation steps: 0.002553546291577527\n",
      "Validation loss per 100 evaluation steps: 0.002557943763105511\n",
      "Validation loss per 100 evaluation steps: 0.0027393318846280893\n",
      "Validation loss per 100 evaluation steps: 0.002683220554704729\n",
      "Validation Loss: 0.002681933401822085\n",
      "Validation Accuracy: 0.9989453415221548\n"
     ]
    }
   ],
   "source": [
    "labels, predictions = valid(model, testing_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, \"bert_tuned.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, sentence):\n",
    "    inputs = tokenizer(sentence, is_split_into_words=True, padding='max_length', truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
    "    # move to gpu\n",
    "    ids = inputs[\"input_ids\"].to(device)\n",
    "    mask = inputs[\"attention_mask\"].to(device)\n",
    "    # forward pass\n",
    "#     model.to(device)\n",
    "    outputs = model(ids, mask)\n",
    "    logits = outputs[0]\n",
    "    active_logits = logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "    flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size*seq_len,) - predictions at the token level\n",
    "\n",
    "    tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n",
    "    token_predictions = [ix_to_tag[i] for i in flattened_predictions.cpu().numpy()]\n",
    "    wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n",
    "\n",
    "    word_level_predictions = []\n",
    "    for pair in wp_preds:\n",
    "        if (pair[0].startswith(\" ##\")) or (pair[0] in ['[CLS]', '[SEP]', '[PAD]']):\n",
    "            # skip prediction\n",
    "            continue\n",
    "        else:\n",
    "            word_level_predictions.append(pair[1])\n",
    "\n",
    "    # we join tokens, if they are not special ones\n",
    "    str_rep = \" \".join([t[0] for t in wp_preds if t[0] not in ['[CLS]', '[SEP]', '[PAD]']]).replace(\" ##\", \"\")\n",
    "    print(str_rep)\n",
    "    print(word_level_predictions)\n",
    "    \n",
    "    del ids\n",
    "    del mask\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return word_level_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_aug = augment_data_with_tokenizer_test(test)\n",
    "test_aug_batched = batchify_augmented_data_test(test_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• it is accessible to all and does not require significant material investment and can be done quickly • it is scala # # ble • it allows cat # # ego # # rization and linking of information • it can be applied to any type of situation : note # # taking , problem solving , analysis , creation of new ideas • it is suitable for all people and is easy to learn • it is fun and encourages exchanges • it makes visible the dimension of projects , opportunities , inter # # con # # ne # # ctions • it synth # # es # # izes • it makes the project understand # # able\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "word_level_predictions = predict(model, test_aug_batched.tokenized_sentences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "design thinking for innovation reflex # # ion - av # # ril 2021 - nat # # hal # # ie sy # # lla challenge & selection the tool i use to help all stakeholders finding their way through the complexity of a project is the mind map . what exactly is a mind map ? according to the definition of bu # # zan t . and bu # # zan b . ( 1999 , des # # sin # # e - moi l ' intelligence . paris : les editions d ' organisation . ) , the mind map ( or he # # uri # # stic diagram ) is a graphic\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "• it is accessible to all and does not require significant material investment and can be done quickly • it is scala # # ble • it allows cat # # ego # # rization and linking of information • it can be applied to any type of situation : note # # taking , problem solving , analysis , creation of new ideas • it is suitable for all people and is easy to learn • it is fun and encourages exchanges • it makes visible the dimension of projects , opportunities , inter # # con # # ne # # ctions • it synth # # es # # izes • it makes the project understand # # able\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "point generates ideas / work areas , inc # # rem # # ented around this center in a radial structure , which in turn is completed with as many branches as new ideas . this tool enables creativity and logic to be mobilized , it is a map of the thoughts . creativity is enhanced because participants feel comfortable with the method . application & insight i start the process of the mind map creation with the stakeholders standing around a large board ( white or paper board ) . in the center of the board , i write and highlight the topic to design . through a series of questions , i guide the stakeholders in modelling the mind map . i\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "topic to be addressed . in the type of questions , we can use : who , what , when , where , why , how , how much . the use of the “ why ” is very interesting to understand the origin . by this way , the interviewed person free # # s itself from paradigm # # s and thus dare # # s to propose new ideas / ways of functioning . i plan two hours for a workshop . design thinking for innovation reflex # # ion - av # # ril 2021 - nat # # hal # # ie sy # # lla after modelling the mind map on paper , i propose to the participants\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      ". this second workshop also lasts two hours and allows the mind map to evolve . once familiar # # ized with it , the stakeholders discover the power of the tool . then , the second workshop brings out even more ideas and constructive exchanges between the stakeholders . around this new mind map , they have learned to work together and want to make visible the unto # # ld ideas . i now present all the projects i manage in this type of format in order to ease rapid understanding for decision - makers . these presentations are the core of my business models . the decision - makers are thus able to identify the opportunities of the projects and can take\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "they find answers to their questions thank to a sc # # hema # # tic representation . approach what i find amazing with the fa # # ci # # lita # # tion of this type of workshop is the participants commitment for the project . this tool helps to give meaning . the participants appropriate the story and want to keep writing it . then , they easily become actors or sponsors of the project . a trust relationship is built , thus facilitating the implementation of related actions . design thinking for innovation reflex # # ion - av # # ril 2021 - nat # # hal # # ie sy # # lla annex\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "diego estrada design thinking assignment visual # # ization tool challenge & selection the elderly were having a hard time adapting to the changes we brought in our bank . as a result of a poorly implemented linear solution , a more customer cent # # ric approach was needed . after learning about design thinking in this course , we decided to apply it to solve this problem . the visual # # ization tool allowed the team to create a dynamic presentation using diagrams , figures and drawings on the go that really res # # onate # # d among the stakeholders . previous to this change , none of our solutions seemed to be adequate for them ,\n",
      "['B-NAME_STUDENT', 'I-NAME_STUDENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "understand the problem in the way the team and i did . application the process starts in the prep time . the team uses a series of tools and software to develop a presentation using the surveys gathered during research and the solutions we created during the process . the use of graphs to quickly show statistics in a fully visual way , rather than verbal # # ly was a game change # # r . after having a presentation prepared , the team hands an activity to the stakeholders , where the solutions discussed previously appear . nonetheless , the solutions need more work to them . after this . the stakeholders are asked to help complete the solutions while the team and\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "to represent how their suggestions would impact on this specific problem . the use of a group activity strengthen # # s the bond between the company and their investors . it makes them feel like they take part and help solve the problems as well as show how customer cent # # ric the solutions are . every complaint and suggestion from customers are read and evaluated using the graph shown in the course ( involving : can we do it ? can we afford it ? … ) . the final # # ization of this activity leaves the team and the stakeholders on the same page . it allows them to completely understand and feel part of the solution and also gives\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "ease # # s the work of the team . insight & approach the use of this method created a new work # # flow in the design team . it increased the productivity and the success rate as well as the customer / stakeholders satisfaction . the use of the visual # # ization tool created an engaged group of people who work together to diego estrada find a solution based on their customer satisfaction . this solution is later revised and t # # we # # ake # # d with the help of the stakeholders who are deeply involved in the process . presentations , graphics , and activities have added a huge increase in satisfaction . as a company\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NAME_STUDENT', 'I-NAME_STUDENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "understanding , but when paired with the adequate process things just flow . ( this story is fictional and was created for solving the assignment )\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "reporting process by gilbert # # o ga # # mbo # # a challenge i received a promotion of being the regional controller , along with my actual position of country cf # # o . the main responsibility of this new position was to weekly report the results for the week and estimate the final results of the month of 4 countries and consolidated those . when i was receiving the position , i went to visit my colleague , former regional controller , who was promoted to country ceo and now had interest conflicts of being the controller . the process to consolidate the information of the 4 countries was that the country controllers sent him an email with the main\n",
      "['O', 'O', 'O', 'B-NAME_STUDENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "country accountant who consolidated it , the accountant sent him the consolidated report and he finally reported to the headquarters . the whole process took almost a full business day to complete . given that my responsibilities as country cf # # o demanded more attention because my country had more operations , i decided to change the process in order to reduce the duration and to ensure standardization in the format , and actually , reduce the human intervention , making that the country controllers work directly in the consolidation file . selection having in mind that there was a different kind of users of file , i select some of those to determine what was the main important things to take into account in\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "process of the information and the reading of the same . in that sense , we form a group of the country controllers , country ceo # # s , it guys , and people from the headquarters to find the best solutions possible . application for the first lunch , we focused on the consolidation process in order to avoid the copy - paste processes and reducing the manual intervention so , we build an online application where all the controllers fill the figure of their respective country , along with the comments . during the first week of the first stage , we sent the new report along with the old one , and after the meeting with the headquarters team , we ask\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "meeting review of the new format , all the assistants provided their comments and suggestions that were the input for the next report . for the second lunch , we focused on the feedback received from the assistants to the review meeting , we adjust the report and we were able to eliminate the old one . the final report included all the suggestions received but the best of all is that reduced the time investment from about 36 men hours to around 8 , without missing any valuable information and including new data that the stakeholders appreciated so much . insight with the application of the learning launch tool , the controller ’ s team along with the main stakeholders identified different assumptions and designed\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "test these assumptions . on the other hand , we found probable requirements from headquarters , expecting to find that a more agile approach that improved the work # # flow , reduced the time investment of everyone in the team and that both our team and the key stakeholders were very satisfied with the results of the exercise and the new report . the final report was slightly different from what we anticipated , but the differences were more related to form and a few topics to be included in the report . approach despite that , the team was not used to design thinking tools , they were able to work with the learning launch that was the appropriate tool . the team needs\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "gained from our first two launches and continuously evaluate this insight and new ones into future launch designs , especially taking into account that the full automation of the reports will take at least 4 years more according to the er # # p implementation plan of the head # # qua # # rter .\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "design thinking for innovation sin # # dy sam # # aca gi # # tam university december , 2021 challenge my challenge to solve is the problem of a company that is without sufficient capital to create and build its own industrial plant , and can not cope with the growing demand that they have had in the last two months . the company is in a dilemma , as it has two potential investors ; the first investor offers the amount of capital necessary for the creation of the plant , in return he asks to intervene in the process and make certain changes in the final product since he thinks that the idea he has has shown good results in\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "in the company , the second investor offers the capital necessary for the creation of the plant in exchange for do not make modifications to the final product , since this is the one that is generating the exponential growth of the company , for the moment it is only asked to focus on the company ' s success product and as they recover the investment they can be extended to the innovation of products and creation for a 20 % stake within the company . as a manager of the company , i need to make the best decision for the above mentioned one . selection i decided to choose the visual # # ization tool , visual # # ization allows me\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "be able to define the needs and their possible solutions . this tool is useful for me to have a clearer vision of the current state of the company and what it ultimately requires ; through this tool i can de # # du # # ce the personalities of the two investors , such as george and geoff ; and based on this i can make the best decision . application in the application of my chosen tool to the challenge that i have set myself , the tool has been of a very wide utility , since when applying it to my challenge very good results were obtained , since with this i could have an analysis to the measure of the two investors\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "with my visual # # ization tool was to conduct a study to customers who required the flagship product of the company , first i had to understand why the demand had had such a strong growth in the last two months , by applying the tool i could find the answers to this question ; i could see that customers needed this product as it was , without any modification because the product worked wonders . with this study of the clients interested in the product , i was able to analyze and follow up on the proposals i had on the table from the two investors . i concluded that i needed the person who was interested in the first instance to supply\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "great success . which was the second investor , since he was interested in first of all to give the size of production that our customers demanded , and then worry about improving it , but in small and con # # cise steps . i discarded the first investor , as he did not meet the requirements that the company needed at that time . i realized that this investor was convinced that by changing the product to the way he thought , the demand was going to increase more ; but in reality what the company needed was to be able to cover the demand that the product was having , this investor wanted to throw everything we had , to the side\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he did not think for a moment that these modifications should have a low impact in case things do not go as well as expected . thanks to the application of the tool i was able to identify the key points of the company ' s needs and how each investor , according to their proposals , could help me , based on this i made the best decision . i chose to work with the second investor , we were able to supply the demand for the product , then the investment triple # # d and we were able to in # # ject it into research for product innovation , and make some small changes , which were being introduced to customers\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "when customers became more interested in the improved product , we decided to increase production by improving the product . perspective the information and the final lesson that i had when social # # izing what we obtained by using the visual # # ization tool , the first thing is that we must always think first about the needs of customers , of the people interested in the product ; it is very useful to know what the problem is , what is the cause of the problem and finally build an effective solution . secondly , based on what we have obtained , we can find a partner that fits our needs , and be able to work as a team ,\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "thanks to the knowledge gained from the design course , i was able to create a strategic plan for the company ' s problems and make it a successful plan . approach what i would apply differently in the challenge would be the tool used , i would like to use the learning launch ; i would do it in the following way , rejecting the proposals of the two investors and only creating the way that the production process would be decreased to be able to supply the required demand . it may or may not work out , but i would like to have employed this strategy .\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "assignment : visual # # ization reflection submitted by : nad # # ine born course : design thinking for innovation trail challenge : to build or not to build an environmental charity wanted to conduct a fundraising campaign to raise $ 4 million to build a public path in a busy tourist area of a small town in british columbia , canada . they had been gifted a large piece of land by a local landowner , which was a substantial gift and prevented them from needing to purchase the land , however , they still needed to raise a large amount of money in order to pay for the supplies and labor to build the trail . even though the local\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NAME_STUDENT', 'O', 'O', 'B-NAME_STUDENT', 'B-NAME_STUDENT', 'I-NAME_STUDENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      ", they could not provide enough money from private donations to build it . if the summer vacation property owners did not provide some funding , then there was a strong possibility that they would not raise enough money to complete the trail . the charity did not know if the community as a whole would support the project and needed to conduct testing with key influence # # rs and potential donors to gauge their interest . building the trail without testing the support first was too risky because the charity did not have enough money in reserve to cover the cost of the trail if the fundraising efforts were not successful . tool selection : visual # # ization visual # # i\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "ideas into a compelling story that can generate vivid mental images ” ( designing for growth , p # # 49 ) . as the consultant for the study , i chose visual # # ization because the charity had a firm concept of why they needed the trail , how it would benefit the town , and how much it would cost but needed a per # # su # # asi # # ve way to tie it all together . the business case for the project was strong but without a tool to help them illustrate how the trail would positively impact the residents , there was little chance people would donate enough to meet the budget . we needed a\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "support the project . visual # # ization provided the perfect combination of key messaging , beautiful photography , architectural rendering # # s , safety data , and budget criteria to create the vision for the project in an easy ‐ to ‐ read document that was only four pages in length . visual # # ization allowed us to describe the urgent and compelling need for the trail in a su # # cci # # nc # # t and tangible way . application once we drafted the vision document , we worked with the charity to identify a list of people whose opinion would be important to the success ( or failure ) of the fundraising campaign . the\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "and business owners , affluent summer ‐ only residents , and elected officials . we requested one ‐ hour meetings with all of the people on the list . if people did not want to meet with us in person , which was often the case with the part ‐ time residents , we offered to conduct the meetings by phone . when someone agreed to meet with us , we email # # ed them the vision document so they could read it in advance and prepare their questions . this created a good environment for an informed and candi # # d dialogue . while the scheduling of the interviews was in progress , we designed a question # # naire to guide\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "that we covered the same questions with all the interview # # ees . the goal was to speak with 20 – 25 key influence # # rs in the community and gauge their interest in , or opposition to , supporting the fundraising efforts for the trail as either donors or campaign volunteers or both . we successfully met with 24 interview # # ees and compiled the feedback into a summary report along with recommendations for the charity . the entire process took three months . insight fundraising and design thinking both require a willingness to adapt and fail fast . good fundraiser # # s are responsive to their donors and design thinking serves as the perfect platform to plan and\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "complex philanthropic issues . we are not formally taught design thinking models in fundraising classes but they should be added to the curriculum . although it is not explicitly stated in the course videos , it occurred to me that both fundraising and design thinking are rooted in communication and relationships and both are it # # erative processes based on testing and investigation . the elusive syn # # ergy between art and science is as beautifully illustrated by design thinking as it is as inherent in daily fundraising practice . improvements for next time visual # # ization was an effective tool in this circumstance and i would use it again in a similar situation . however , it would also\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "wide spectrum of people from the town because there were many assumptions made during the visual # # ization process about how the trail would be used and what benefits would be desired by the tourists , local public , and sponsors . journey mapping would have confirmed the validity of those assumptions and supplemented the data gathered during the interviews . the other tool that i would use next time in conjunction with visual # # ization is storytelling . i would take someone ’ s first hand account of the situation and create a short video to showcase the urgency of the project or program from his / her perspective . a link to the video would be included in the email\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "the vision document . i think this would provide a ho # # listic micro and macro perspective to the exercise and spark some interesting conversations in the interviews .\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "cheese startup - learning launch by el # # adi # # o ama # # ya challenge we are a small company in barcelona ( spain ) that ref # # ines high - quality organic cheese # # s from small producers in the pyrenees . we also trade milk and yo # # gur # # ts from these producers . we distribute our dairy products mainly to haute cuisine restaurants ( 60 % of our turnover ) and to delicate # # sen # # s stores ( 35 % of our turnover ) , the remaining 5 % we distribute to individuals , mainly family , friends and acquaintances . selection i have chosen the \" learning launch\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-NAME_STUDENT', 'O', 'O', 'B-NAME_STUDENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "corona # # virus crisis , all restaurants have closed and delicate # # sen store sales have dropped dramatically . therefore we have had to change our target niche and head towards private individuals and common stores . we have carried out a survey both in small stores and among individuals . in the survey we asked what types of cheese are the most willing to consume , as well as milk and yo # # gur # # ts , also the type of milk ( goat , cow , sheep ) , the level of cu # # ring and the price they would be willing to pay for our products . we have also proposed sending boxes with different products on\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "survey and the observations of individuals and small stores , we have focused our offer on a certain type of product , we have distributed it and analyzed the result not only with our customers but also with objective sales figures . insight the result has been spectacular , our weekly turnover had fallen to 25 % with a loss of 75 % ( 60 % of restaurants and 15 % of delicate # # ssen stores ) . the situation was dramatic but nowadays sales to individuals have risen from 5 % to 25 % and common food stores have gone from 0 % to 15 % . approach our situation is not good , but we hope that when the restaurants open and\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "we will have a much broader portfolio of clients and a way of working based on the client and transferred to the producer . before , we used to transfer products from small producers to customers . now the flow has changed .\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "silvia villa # # lo # # bos challenge : there is a company which provides financial advisory to customers either in person or virtual . lately organisation climate has been seen decay # # ed as result of arguments , has # # sle # # s and the lack of fraternity and cooperation among the campaign workers . the aim is improving climate organisation to transmit unity and trust to our customer . selection : storytelling is the first tool selected , because this tool allows to connect with the audience , to make understand # # able the message , and to transmit emotions . campaign workers would feel identified and understand the importance of tolerance and empathy . application\n",
      "['B-NAME_STUDENT', 'I-NAME_STUDENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "fictional stories , and stories told by participants created a different atmosphere due to participants started to produce deeper relationships among them and recognize the importance of being em # # pathic . an important result was that meeting with clients were longer . approach : the activities work in a good way , but visual # # ization tool would work very well in a challenge like this . showing the way , some elements to get a harmon # # ious atmosphere through visual # # ization is an option in a further situation .\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "storytelling the path to innovation dr sa # # kir ahmad challenge & selection be it any organization , team or a government venture , i have often observed that they experience failures because they could n ’ t connect with their audience apt # # ly . in such scenarios , storytelling can turn the table significantly . i have used the tool ‘ storytelling ’ in my organization to convey a complicated message as simply as possible or to generate ideas from people around me . the idea is to implement this innovative tool to make the intricate issues understand # # able and engage the targeted audience . i relay # # ed the context of the story to capt\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NAME_STUDENT', 'B-NAME_STUDENT', 'I-NAME_STUDENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "in front of my team - members of the organization to imp # # art its essence , brains # # torm notions , make productive connections and develop appropriate strategies . the crucial element in storytelling is to engaging # # ly answer the questions raised in the story to its targeted audience and allow them to res # # onate with the core subject of the story . when i shared the story , i tried to gain the insights from the audience as to how the characters inspire them and how it related to their work emotions . the information and feedback immensely helped me in recognizing its importance in finding solutions in real world . application i used the\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "the essence and impact of revolutionary thinking . i understood that the story has to make sense so that they can comprehend the context and relate with it . i started the story of the time when there was an emergence of deadly diseases due to mosquito # # es i . e . malaria etc . and a company brought a revolution by introducing a range of mosquito rep # # elle # # nt products . i emphasized on its out - of - the box thinking & ideas that made the brand conquer the market . i observed that my audience were sincerely engaged and were emotionally connected with the company . after i finished , there were questions and productive interactions which\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "project . the enthusiasm of thinking af # # resh was quite overwhelming . insight & approach when i anal # # yse # # d the whole series of events it made me wonder , “ did my tool work ? the answer i think is ‘ yes ’ . will it serve the purpose ? i think that time will tell but i believe it will certainly aid them in making apt strategies . ” the exercise portrayed that a revolutionary story can influence a small number of people then storytelling as a design - thinking tool , if implemented efficiently , can bring ground - breaking changes in organizations & countries . i observed that my story engaged my targeted audience\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". as a student of design thinking , i can explore this tool from all corners and can confidently say that i can creative # # ly use it in number of inspiring ways at any appropriate phase of design thinking activities .\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "reflection – learning launch francisco ferreira challenge i take part of a social enter # # pre # # nu # # ers # # hip group in my university . we were in contact with cap # # ao das ant # # as , a rural community in the suburbs of sao carlos ( sp - brazil ) . we had the intention to cr # # iate , with the local producers , a project that wo # # ld improve the quality of life in the neighborhood . for that , in the first two months we begin to listen each farmer of cap # # ao and try identify the principal issues of the place and their resident\n",
      "['O', 'O', 'O', 'O', 'B-NAME_STUDENT', 'I-NAME_STUDENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      ". therefore , we had the objective to make and test a business model that would increase their rent . selection in order to build a sustainable business model with the farmers , we made a first test were we delivered the products at the costume # # r ’ s door . the action had a good result but we want to increase even more ours sales . so we used learning launch # # s to test new idea # # is and then improve our business model . application after we anal # # ise all the data we had and build the business model , its was far from be the most sustainable and profitable one . to improve our project\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "# # ling . so every week , after we anal # # ise all the process from the farm to the costume # # r door , we propose and test # # e the improvement in the current business model . in order to give examples of how it works , after some weeks we notice that the farmers were having problems in separate the orders . the costume # # rs were ordering with na app called what # # sa # # pp , but the person who was res # # pon # # sable for taking note of the orders was messy with the conversations feed . as soon as we notice this problem we proposed a new\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "zero mistakes in separating the orders . insights the application of learning launches showed me how testing is important # # e in building a solid business model . therefore , i learned that the more you test possible # # s id # # eia # # s , more chance of su # # ces # # s you have . testing a lot of improvement and ideas is not the fastest way to achieve a better scenario but is clear # # y a certainly strategy to get there . approach during all the improvement plan that we act every week we propose changes based on what we were seeing during the deliveries . i think that we could have achieved\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "we could have made a better knowledge management of the changes proposed for the business model .\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "gandhi institute of technology and management higher school of economics essay № 1 on economics course topic 7 “ why are people sometimes alt # # ru # # istic ? ” stefano lo # # vat # # o md # # i - 191 student sat # # hya # # ba # # ma april , 2020 in many classical economic theories , it is common to determine a human , as a very ego # # istic creature . adam smith ’ s books ( but not all of them ) were wrote based on this idea also . however , the conception of homo economic # # us was introduced for the first time by john\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NAME_STUDENT', 'I-NAME_STUDENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "pursue their subjective # # ly - defined ends optimal # # ly # # 1 . however , in our real life we face acts of alt # # ru # # ism very often : our parents provide us with all necessary goods , a lot of businessmen give money for charity and even strangers give money to homeless people . so , it is very clear , that people do not necessarily acts in their own interests all the time , they also tend to help others . but what makes them to do this ? why are people sometimes alt # # ru # # istic ? ge # # ras # # hc # # henko\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "been existing from the very times of primitive man , as a single ego # # istic individual was not capable to survive out of his or her community . all resources were so difficult to get , that the efforts of the whole pride were essential in struggle for survival . the following way the system of social values , where helping other people is highly appreciated , started to form . the ideology of individual # # ism instead of collect # # ivism has appeared much time later , when the market economy gave us a possibility to live independently from each other , or to form smaller communities , as nuclear families . but even now , in modern\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "to act in alt # # ru # # istic way . so , let ’ s try to discover , what other motives , besides ancient habit , do they have . one of the mechanisms , which makes people act in alt # # ru # # istic way , is called reciprocal ( or mutual ) alt # # ru # # ism . it means , that individuals tend to help someone , who is likely to give something back . but it does n ’ t mean , that human beings are ego # # istic . people subconscious # # ly wait for the same attitude to them after performing alt # # ru #\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "the purpose for just cooperation as a motive of economic behavior ” , provides us with results of the experiment , which shows the re # # lev # # ancy of the statement , which was made above : both of two players ( a and b ) were provided with a certain amount of money ( a and b respectively ) . firstly , player a is asked to give a part of his money to player b , and after that player b is also asked to give money to a . both players are free to choose any amount of money ( x or y respectively ) they want to give or not to give anything at all . the rational\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "give money . because in case , when a decided to share , it would not be profitable for b to share money ( b + x # # a — y # # b < b + x # # a ) . and if a decided not to give money , b would not give money either . however , in reality , when the experiment took place , the results showed that 20 of 30 pairs of students shared their money . the average received sum of money were 32 , 5 % of the initial one . but in case , when one of the players 1 the definition is taken from https : / / en . wikipedia . org /\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-URL_PERSONAL', 'B-URL_PERSONAL', 'B-URL_PERSONAL', 'B-URL_PERSONAL', 'B-URL_PERSONAL', 'B-URL_PERSONAL', 'B-URL_PERSONAL', 'B-URL_PERSONAL', 'B-URL_PERSONAL', 'B-URL_PERSONAL']\n",
      "2 treat people the way you want to be treated . player a / player b to give money not to give to give money a + y # # b — x # # a , b + x # # a — y # # b a — x # # a , b + x # # a not to give a + y # # b , b — y # # b a , b denied the opportunity of cooperation ones , in most of the cases it put the end for the future transaction , as the condition of relic # # ense was lost . one more thing , which can help us to understand the phenomenon of\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "“ dictator ” , “ ultimatum ” and “ the division of the public good ” . in “ dictator ” game one the players receives a sum of money , part of which he / she can give to another player . the rational behavior , which is expected from the first person , is not to give anything , as only in this case he / she will get the maximum possible profit . strangely , but in 61 # # 6 experiments # # 3 , which were carried out , an average given sum was about 28 , 35 % of the initial sum and only about 1 / 3 of all participants gave nothing . the motive for such alt #\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "of justice , as the first person did nothing in order to get money , so he / she thinks , that it would be fair to share them . another explanation of alt # # ru # # ism is people ’ s consciousness about their reputation . as i mentioned above , alt # # ru # # ism is socially approved behavior , so individuals , who are known for helping people around , may be in more respect , than others . so , the motives for the alt # # ru # # istic actions can be not only empathy , but also concern for the opinion of others . charity donations are a good example of an\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "most of the charity cases only small donations are made anonymous # # ly , but names of people , who donate huge amounts of money , are usually well - known and numerous times mentioned in newspapers , magazines and tv programs . so , philanthropist # # s may expect more support from the society , if they need , as they are known as a good person . developing the idea about philanthropy , we face another reason for being alt # # ru # # istic . this motive is about being conscious of the future of the civilization , also known as communal interest , which differ people from animals . people want to live in comfortable conditions ,\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "so , they are ready to contribute to the common good in order to provide their families and themselves with better life . that is why the idea of social alt # # ru # # ism appeared . scientists faced the fact , that they are unable to explain why people continue help others even , when they do not have any fi # # lia # # tion at all . this type of behavior started to take place , when human ’ s intentions goes beyond family and reputation # # al alt # # ru # # ism . ernst fe # # hr and ur # # s fis # # ch # # bach # # er\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NAME_STUDENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re # # mun # # eration or alt # # ru # # istic punishment ( stigma # # ti # # zation ) . taking all things into consideration , we can conclude , that alt # # ru # # ism has a significant economic effect not only on one particular person or a small social group , but on the whole society . and strange , as it may seem , alt # # ru # # istic behavior can be profitable for the alt # # ru # # ist as well as for someone , who receives help . moreover , many social organizations , even economic ones , would not work at all\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "system . 3 kazan # # ts # # eva t . v . alt # # ru # # ism : the phenomenon and operational # # ization ( https : / / cyber # # len # # ink # # a . ru / article / n / st # # rem # # len # # ie - k - sp # # rave # # dl # # ivo # # mu - so # # tr # # ud # # nic # # hes # # tv # # u - ka # # k - mo # # tiv - ek # # ono # # mic # # hes # #\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NAME_STUDENT', 'B-URL_PERSONAL', 'O', 'I-NAME_STUDENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-URL_PERSONAL', 'B-URL_PERSONAL', 'B-URL_PERSONAL', 'B-URL_PERSONAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "2018 / 36 # # 39 # # 8 - et # # iche # # sko # # e - uc # # hen # # ie - as # # mit # # a - v - ko # # nte # # ks # # te - so # # vre # # men # # no # # y - ek # # ono # # mi # # ki . html ) . 2 . sh # # ma # # kov a . v . purpose for just cooperation as motives of economic behavior / / terra economic # # us . 2010 . ( https : / / cyber # # len # #\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "k - sp # # rave # # dl # # ivo # # mu - so # # tr # # ud # # nic # # hes # # tv # # u - ka # # k - mo # # tiv - ek # # ono # # mic # # hes # # ko # # go - po # # ved # # eni # # ya ) . 4 . andre # # oni j . philanthropy / / handbook of giving , alt # # ru # # ism , and rec # # ip # # rocity . vol . 2 / s . ko # # lm\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "5 . fe # # hr e . , schmidt k . m . the economics of fairness , rec # # ip # # rocity and alt # # ru # # ism – experimental evidence and new theories / / handbook of the economics of giving , alt # # ru # # ism and rec # # ip # # rocity . 2006 . ( https : / / www . mel # # ess # # a . un # # i - mu # # en # # chen . de / team / vo # # rst # # ands # # sp # # re # # cher / schmidt / pub\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-URL_PERSONAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n",
      "/tmp/ipykernel_4983/4208203702.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_aug_batched['labels'][i] = word_level_predictions\n"
     ]
    }
   ],
   "source": [
    "test_aug_batched['labels'] = np.empty((len(test_aug_batched), 0)).tolist()\n",
    "for i in range(len(test_aug_batched)):\n",
    "    word_level_predictions = predict(model, test_aug_batched.tokenized_sentences[i])\n",
    "    test_aug_batched['labels'][i] = word_level_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenized_sentences</th>\n",
       "      <th>document</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[CLS], design, thinking, for, innovation, ref...</td>\n",
       "      <td>7</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[•, it, is, accessible, to, all, and, does, no...</td>\n",
       "      <td>7</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[point, generates, ideas, /, work, areas, ,, i...</td>\n",
       "      <td>7</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[topic, to, be, addressed, ., in, the, type, o...</td>\n",
       "      <td>7</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[., this, second, workshop, also, lasts, two, ...</td>\n",
       "      <td>7</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>[re, ##mun, ##eration, or, alt, ##ru, ##istic,...</td>\n",
       "      <td>123</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>[system, ., 3, kazan, ##ts, ##eva, t, ., v, .,...</td>\n",
       "      <td>123</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, B-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>[2018, /, 36, ##39, ##8, -, et, ##iche, ##sko,...</td>\n",
       "      <td>123</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>[k, -, sp, ##rave, ##dl, ##ivo, ##mu, -, so, #...</td>\n",
       "      <td>123</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>[5, ., fe, ##hr, e, ., ,, schmidt, k, ., m, .,...</td>\n",
       "      <td>123</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  tokenized_sentences  document  \\\n",
       "0   [[CLS], design, thinking, for, innovation, ref...         7   \n",
       "1   [•, it, is, accessible, to, all, and, does, no...         7   \n",
       "2   [point, generates, ideas, /, work, areas, ,, i...         7   \n",
       "3   [topic, to, be, addressed, ., in, the, type, o...         7   \n",
       "4   [., this, second, workshop, also, lasts, two, ...         7   \n",
       "..                                                ...       ...   \n",
       "61  [re, ##mun, ##eration, or, alt, ##ru, ##istic,...       123   \n",
       "62  [system, ., 3, kazan, ##ts, ##eva, t, ., v, .,...       123   \n",
       "63  [2018, /, 36, ##39, ##8, -, et, ##iche, ##sko,...       123   \n",
       "64  [k, -, sp, ##rave, ##dl, ##ivo, ##mu, -, so, #...       123   \n",
       "65  [5, ., fe, ##hr, e, ., ,, schmidt, k, ., m, .,...       123   \n",
       "\n",
       "                                               labels  \n",
       "0   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "1   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "2   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "3   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "4   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "..                                                ...  \n",
       "61  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "62  [O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, B-...  \n",
       "63  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "64  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "65  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "\n",
       "[66 rows x 3 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_aug_batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>document</th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>482</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>483</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>741</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>742</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>464</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>465</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>56</td>\n",
       "      <td>12</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>56</td>\n",
       "      <td>13</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>86</td>\n",
       "      <td>6</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>86</td>\n",
       "      <td>7</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>104</td>\n",
       "      <td>8</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>104</td>\n",
       "      <td>9</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>112</td>\n",
       "      <td>5</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>6</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>123</td>\n",
       "      <td>32</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>123</td>\n",
       "      <td>33</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    row_id  document  token           label\n",
       "0        0         7      9  B-NAME_STUDENT\n",
       "1        1         7     10  I-NAME_STUDENT\n",
       "2        2         7    482  B-NAME_STUDENT\n",
       "3        3         7    483  I-NAME_STUDENT\n",
       "4        4         7    741  B-NAME_STUDENT\n",
       "5        5         7    742  I-NAME_STUDENT\n",
       "6        6        10      0  B-NAME_STUDENT\n",
       "7        7        10      1  I-NAME_STUDENT\n",
       "8        8        10    464  B-NAME_STUDENT\n",
       "9        9        10    465  I-NAME_STUDENT\n",
       "10      10        16      4  B-NAME_STUDENT\n",
       "11      11        16      5  I-NAME_STUDENT\n",
       "12      12        20      5  B-NAME_STUDENT\n",
       "13      13        20      6  I-NAME_STUDENT\n",
       "14      14        56     12  B-NAME_STUDENT\n",
       "15      15        56     13  I-NAME_STUDENT\n",
       "16      16        86      6  B-NAME_STUDENT\n",
       "17      17        86      7  I-NAME_STUDENT\n",
       "18      18        93      0  B-NAME_STUDENT\n",
       "19      19        93      1  I-NAME_STUDENT\n",
       "20      20       104      8  B-NAME_STUDENT\n",
       "21      21       104      9  I-NAME_STUDENT\n",
       "22      22       112      5  B-NAME_STUDENT\n",
       "23      23       112      6  I-NAME_STUDENT\n",
       "24      24       123     32  B-NAME_STUDENT\n",
       "25      25       123     33  I-NAME_STUDENT"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4983/2223476174.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moriginal_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreverse_tokenization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mpreserved_labels_this_doc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mpreserved_tokens_this_doc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'document'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tokens'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpreserved_tokens_this_doc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'labels'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpreserved_labels_this_doc\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;31m# result.append({'document': doc, 'tokens': preserved_tokens_this_doc, 'labels': preserved_labels_this_doc}, ignore_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5985\u001b[0m         \"\"\"\n\u001b[1;32m   5986\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mrandom\u001b[0m \u001b[0msample\u001b[0m \u001b[0mof\u001b[0m \u001b[0mitems\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0man\u001b[0m \u001b[0maxis\u001b[0m \u001b[0mof\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5988\u001b[0m         \u001b[0mYou\u001b[0m \u001b[0mcan\u001b[0m \u001b[0muse\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mreproducibility\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5989\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5990\u001b[0m         \u001b[0mParameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5991\u001b[0m         \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5992\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "result = pd.DataFrame()\n",
    "result['document'] = []\n",
    "result['tokens'] = []\n",
    "result['labels'] = []\n",
    "\n",
    "for doc in test_aug_batched.document.unique():\n",
    "    df_this_doc = test_aug_batched[test_aug_batched.document == doc]\n",
    "    preserved_labels_this_doc = []\n",
    "    preserved_tokens_this_doc = []\n",
    "    for i in range(len(df_this_doc)):\n",
    "        labels = df_this_doc['labels'][i]\n",
    "        tokens = df_this_doc['tokenized_sentences'][i]\n",
    "        original_tokens, original_labels = reverse_tokenization(tokens, labels)\n",
    "        preserved_labels_this_doc.extend(original_labels)\n",
    "        preserved_tokens_this_doc.extend(original_tokens)\n",
    "    print(type(result))\n",
    "    result = result.append({'document': doc, 'tokens': preserved_tokens_this_doc, 'labels': preserved_labels_this_doc}, ignore_index=True)\n",
    "    # result.append({'document': doc, 'tokens': preserved_tokens_this_doc, 'labels': preserved_labels_this_doc}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_list = []\n",
    "\n",
    "for doc in test_aug_batched.document.unique():\n",
    "    df_this_doc = test_aug_batched[test_aug_batched.document == doc]\n",
    "    preserved_labels_this_doc = []\n",
    "    preserved_tokens_this_doc = []\n",
    "    for i in range(len(df_this_doc)):\n",
    "        labels = df_this_doc['labels'].iloc[i]\n",
    "        tokens = df_this_doc['tokenized_sentences'].iloc[i]\n",
    "        original_tokens, original_labels = reverse_tokenization(tokens, labels)\n",
    "        preserved_labels_this_doc.extend(original_labels)\n",
    "        preserved_tokens_this_doc.extend(original_tokens)\n",
    "    dict1 = {'document': doc, 'tokens': preserved_tokens_this_doc, 'labels': preserved_labels_this_doc}\n",
    "    rows_list.append(dict1)\n",
    "\n",
    "result = pd.DataFrame(rows_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>[design, thinking, for, innovation, reflex, -,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>[diego, estrada, design, thinking, assignment,...</td>\n",
       "      <td>[I-NAME_STUDENT, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>[reporting, process, by, gilbert, ga, challeng...</td>\n",
       "      <td>[O, O, B-NAME_STUDENT, O, O, O, O, O, O, O, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>[design, thinking, for, innovation, sin, sam, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>[assignment, :, visual, reflection, submitted,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, B-NAME_STUDENT,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>86</td>\n",
       "      <td>[cheese, startup, -, learning, launch, by, el,...</td>\n",
       "      <td>[O, O, O, O, O, B-NAME_STUDENT, O, O, B-NAME_S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>93</td>\n",
       "      <td>[silvia, villa, challenge, :, there, is, a, co...</td>\n",
       "      <td>[I-NAME_STUDENT, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>104</td>\n",
       "      <td>[storytelling, the, path, to, innovation, dr, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, B-NAME_STUDENT, B-NAM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>112</td>\n",
       "      <td>[reflection, –, learning, launch, francisco, f...</td>\n",
       "      <td>[O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>123</td>\n",
       "      <td>[gandhi, institute, of, technology, and, manag...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document                                             tokens  \\\n",
       "0         7  [design, thinking, for, innovation, reflex, -,...   \n",
       "1        10  [diego, estrada, design, thinking, assignment,...   \n",
       "2        16  [reporting, process, by, gilbert, ga, challeng...   \n",
       "3        20  [design, thinking, for, innovation, sin, sam, ...   \n",
       "4        56  [assignment, :, visual, reflection, submitted,...   \n",
       "5        86  [cheese, startup, -, learning, launch, by, el,...   \n",
       "6        93  [silvia, villa, challenge, :, there, is, a, co...   \n",
       "7       104  [storytelling, the, path, to, innovation, dr, ...   \n",
       "8       112  [reflection, –, learning, launch, francisco, f...   \n",
       "9       123  [gandhi, institute, of, technology, and, manag...   \n",
       "\n",
       "                                              labels  \n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "1  [I-NAME_STUDENT, O, O, O, O, O, O, O, O, O, O,...  \n",
       "2  [O, O, B-NAME_STUDENT, O, O, O, O, O, O, O, O,...  \n",
       "3  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "4  [O, O, O, O, O, O, O, O, O, O, B-NAME_STUDENT,...  \n",
       "5  [O, O, O, O, O, B-NAME_STUDENT, O, O, B-NAME_S...  \n",
       "6  [I-NAME_STUDENT, O, O, O, O, O, O, O, O, O, O,...  \n",
       "7  [O, O, O, O, O, O, O, O, B-NAME_STUDENT, B-NAM...  \n",
       "8  [O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O, O...  \n",
       "9  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
