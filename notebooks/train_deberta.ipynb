{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import argparse\n",
    "from itertools import chain\n",
    "from functools import partial\n",
    "import torch\n",
    "from transformers import AutoTokenizer, Trainer, TrainingArguments\n",
    "from transformers import AutoModelForTokenClassification, DataCollatorForTokenClassification\n",
    "import evaluate\n",
    "from datasets import Dataset, features\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sentencepiece\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils.data_handler import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/home/kd/Documents/pii_detection/data/'\n",
    "OUTPUT_DIR = '/home/kd/Documents/pii_detection/models/'\n",
    "TRAINING_MODEL_PATH = \"microsoft/deberta-v3-large\"\n",
    "TRAINING_MAX_LENGTH = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original datapoints:  6807\n",
      "external datapoints:  4434\n",
      "moredata datapoints:  2000\n",
      "combined:  7333\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "368a4648a182499b8088fdd640e30c69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92ae11003671460fa32c182ef040605c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/580 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba0bf05827804dbfaee02d0afc618ebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/home/kd/anaconda3/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:470: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82713aab365f4c34a17cb346f31dc6fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=3):   0%|          | 0/7333 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "data = do_load_data(DATA_PATH)\n",
    "all_labels = sorted(list(set(chain(*[x[\"labels\"] for x in data]))))\n",
    "label2id = {l: i for i,l in enumerate(all_labels)}\n",
    "id2label = {v:k for k,v in label2id.items()}\n",
    "\n",
    "target = [\n",
    "    'B-EMAIL', 'B-ID_NUM', 'B-NAME_STUDENT', 'B-PHONE_NUM', \n",
    "    'B-STREET_ADDRESS', 'B-URL_PERSONAL', 'B-USERNAME', 'I-ID_NUM', \n",
    "    'I-NAME_STUDENT', 'I-PHONE_NUM', 'I-STREET_ADDRESS', 'I-URL_PERSONAL'\n",
    "]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(TRAINING_MODEL_PATH)\n",
    "\n",
    "ds = do_hf_dataset(tokenizer, label2id, data, TRAINING_MAX_LENGTH=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(example, tokenizer, label2id, max_length):\n",
    "\n",
    "    # rebuild text from tokens\n",
    "    text = []\n",
    "    labels = []\n",
    "\n",
    "    for t, l, ws in zip(\n",
    "        example[\"tokens\"], example[\"provided_labels\"], example[\"trailing_whitespace\"]\n",
    "    ):\n",
    "        text.append(t)\n",
    "        labels.extend([l] * len(t))\n",
    "\n",
    "        if ws:\n",
    "            text.append(\" \")\n",
    "            labels.append(\"O\")\n",
    "\n",
    "    # actual tokenization\n",
    "    tokenized = tokenizer(\"\".join(text), return_offsets_mapping=True, max_length=max_length)\n",
    "\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    text = \"\".join(text)\n",
    "    token_labels = []\n",
    "\n",
    "    for start_idx, end_idx in tokenized.offset_mapping:\n",
    "        # CLS token\n",
    "        if start_idx == 0 and end_idx == 0:\n",
    "            token_labels.append(label2id[\"O\"])\n",
    "            continue\n",
    "\n",
    "        # case when token starts with whitespace\n",
    "        if text[start_idx].isspace():\n",
    "            start_idx += 1\n",
    "\n",
    "        token_labels.append(label2id[labels[start_idx]])\n",
    "\n",
    "    length = len(tokenized.input_ids)\n",
    "\n",
    "    return {**tokenized, \"labels\": token_labels, \"length\": length}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['full_text', 'document', 'tokens', 'trailing_whitespace', 'provided_labels', 'input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'labels', 'length'],\n",
       "    num_rows: 7333\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import recall_score, precision_score\n",
    "from seqeval.metrics import classification_report\n",
    "from seqeval.metrics import f1_score\n",
    "\n",
    "def compute_metrics(p, all_labels):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [all_labels[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [all_labels[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    \n",
    "    recall = recall_score(true_labels, true_predictions)\n",
    "    precision = precision_score(true_labels, true_predictions)\n",
    "    f1_score = (1 + 5*5) * recall * precision / (5*5*precision + recall)\n",
    "    \n",
    "    results = {\n",
    "        'recall': recall,\n",
    "        'precision': precision,\n",
    "        'f1': f1_score\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "207202ddc6464781af72f12cf0a95cb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/874M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    TRAINING_MODEL_PATH,\n",
    "    num_labels=len(all_labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "collator = DataCollatorForTokenClassification(tokenizer, pad_to_multiple_of=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I actually chose to not use any validation set. This is only for the model I use for submission.\n",
    "args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR, \n",
    "    fp16=True,\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    report_to=\"none\",\n",
    "    evaluation_strategy=\"no\",\n",
    "    do_eval=False,\n",
    "    save_total_limit=1,\n",
    "    logging_steps=20,\n",
    "    lr_scheduler_type='cosine',\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.01\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model, \n",
    "    args=args, \n",
    "    train_dataset=ds,\n",
    "    data_collator=collator, \n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=partial(compute_metrics, all_labels=all_labels),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d9f27acee004ceea720d9aa866784bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2751 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.8193, 'learning_rate': 1.1594202898550726e-06, 'epoch': 0.02}\n",
      "{'loss': 1.9754, 'learning_rate': 2.6086956521739132e-06, 'epoch': 0.04}\n",
      "{'loss': 0.4636, 'learning_rate': 4.057971014492754e-06, 'epoch': 0.07}\n",
      "{'loss': 0.1061, 'learning_rate': 5.507246376811595e-06, 'epoch': 0.09}\n",
      "{'loss': 0.0533, 'learning_rate': 6.956521739130435e-06, 'epoch': 0.11}\n",
      "{'loss': 0.037, 'learning_rate': 8.405797101449275e-06, 'epoch': 0.13}\n",
      "{'loss': 0.0268, 'learning_rate': 9.855072463768118e-06, 'epoch': 0.15}\n",
      "{'loss': 0.0169, 'learning_rate': 1.1304347826086957e-05, 'epoch': 0.17}\n",
      "{'loss': 0.0091, 'learning_rate': 1.2753623188405797e-05, 'epoch': 0.2}\n",
      "{'loss': 0.0136, 'learning_rate': 1.420289855072464e-05, 'epoch': 0.22}\n",
      "{'loss': 0.0182, 'learning_rate': 1.565217391304348e-05, 'epoch': 0.24}\n",
      "{'loss': 0.012, 'learning_rate': 1.710144927536232e-05, 'epoch': 0.26}\n",
      "{'loss': 0.0156, 'learning_rate': 1.8550724637681162e-05, 'epoch': 0.28}\n",
      "{'loss': 0.015, 'learning_rate': 2e-05, 'epoch': 0.31}\n",
      "{'loss': 0.0084, 'learning_rate': 1.9996777773909093e-05, 'epoch': 0.33}\n",
      "{'loss': 0.0107, 'learning_rate': 1.9987113172184562e-05, 'epoch': 0.35}\n",
      "{'loss': 0.0101, 'learning_rate': 1.9971012423132776e-05, 'epoch': 0.37}\n",
      "{'loss': 0.0098, 'learning_rate': 1.9948485902804472e-05, 'epoch': 0.39}\n",
      "{'loss': 0.0074, 'learning_rate': 1.9919548128307954e-05, 'epoch': 0.41}\n",
      "{'loss': 0.0092, 'learning_rate': 1.9884217748453625e-05, 'epoch': 0.44}\n",
      "{'loss': 0.0075, 'learning_rate': 1.9842517531735837e-05, 'epoch': 0.46}\n",
      "{'loss': 0.0068, 'learning_rate': 1.9794474351659854e-05, 'epoch': 0.48}\n",
      "{'loss': 0.0053, 'learning_rate': 1.9740119169423337e-05, 'epoch': 0.5}\n",
      "{'loss': 0.0067, 'learning_rate': 1.9679487013963566e-05, 'epoch': 0.52}\n",
      "{'loss': 0.0063, 'learning_rate': 1.961261695938319e-05, 'epoch': 0.55}\n",
      "{'loss': 0.005, 'learning_rate': 1.9539552099769128e-05, 'epoch': 0.57}\n",
      "{'loss': 0.0073, 'learning_rate': 1.946033952142077e-05, 'epoch': 0.59}\n",
      "{'loss': 0.0059, 'learning_rate': 1.9375030272505463e-05, 'epoch': 0.61}\n",
      "{'loss': 0.0065, 'learning_rate': 1.9283679330160726e-05, 'epoch': 0.63}\n",
      "{'loss': 0.0041, 'learning_rate': 1.918634556506454e-05, 'epoch': 0.65}\n",
      "{'loss': 0.0142, 'learning_rate': 1.9083091703496373e-05, 'epoch': 0.68}\n",
      "{'loss': 0.0087, 'learning_rate': 1.8973984286913584e-05, 'epoch': 0.7}\n",
      "{'loss': 0.0062, 'learning_rate': 1.8859093629069057e-05, 'epoch': 0.72}\n",
      "{'loss': 0.0089, 'learning_rate': 1.873849377069785e-05, 'epoch': 0.74}\n",
      "{'loss': 0.0051, 'learning_rate': 1.861226243180201e-05, 'epoch': 0.76}\n",
      "{'loss': 0.0081, 'learning_rate': 1.848048096156426e-05, 'epoch': 0.79}\n",
      "{'loss': 0.0042, 'learning_rate': 1.8343234285922955e-05, 'epoch': 0.81}\n",
      "{'loss': 0.0067, 'learning_rate': 1.8200610852841913e-05, 'epoch': 0.83}\n",
      "{'loss': 0.0051, 'learning_rate': 1.8052702575310588e-05, 'epoch': 0.85}\n",
      "{'loss': 0.0069, 'learning_rate': 1.7899604772111163e-05, 'epoch': 0.87}\n",
      "{'loss': 0.0054, 'learning_rate': 1.7741416106390828e-05, 'epoch': 0.89}\n",
      "{'loss': 0.0109, 'learning_rate': 1.757823852207877e-05, 'epoch': 0.92}\n",
      "{'loss': 0.0044, 'learning_rate': 1.7410177178188917e-05, 'epoch': 0.94}\n",
      "{'loss': 0.003, 'learning_rate': 1.72373403810507e-05, 'epoch': 0.96}\n",
      "{'loss': 0.0028, 'learning_rate': 1.7059839514511565e-05, 'epoch': 0.98}\n",
      "{'loss': 0.0033, 'learning_rate': 1.6877788968156172e-05, 'epoch': 1.0}\n",
      "{'loss': 0.004, 'learning_rate': 1.6691306063588583e-05, 'epoch': 1.03}\n",
      "{'loss': 0.0064, 'learning_rate': 1.6500510978824928e-05, 'epoch': 1.05}\n",
      "{'loss': 0.0061, 'learning_rate': 1.6305526670845225e-05, 'epoch': 1.07}\n",
      "{'loss': 0.004, 'learning_rate': 1.6106478796354382e-05, 'epoch': 1.09}\n",
      "{'loss': 0.0045, 'learning_rate': 1.5903495630803302e-05, 'epoch': 1.11}\n",
      "{'loss': 0.0033, 'learning_rate': 1.569670798572239e-05, 'epoch': 1.13}\n",
      "{'loss': 0.0036, 'learning_rate': 1.5486249124420702e-05, 'epoch': 1.16}\n",
      "{'loss': 0.0053, 'learning_rate': 1.5272254676105026e-05, 'epoch': 1.18}\n",
      "{'loss': 0.0025, 'learning_rate': 1.5054862548474298e-05, 'epoch': 1.2}\n",
      "{'loss': 0.003, 'learning_rate': 1.4834212838845639e-05, 'epoch': 1.22}\n",
      "{'loss': 0.003, 'learning_rate': 1.4610447743869313e-05, 'epoch': 1.24}\n",
      "{'loss': 0.0061, 'learning_rate': 1.4383711467890776e-05, 'epoch': 1.26}\n",
      "{'loss': 0.0048, 'learning_rate': 1.4154150130018867e-05, 'epoch': 1.29}\n",
      "{'loss': 0.0044, 'learning_rate': 1.3921911669960055e-05, 'epoch': 1.31}\n",
      "{'loss': 0.0045, 'learning_rate': 1.3687145752679409e-05, 'epoch': 1.33}\n",
      "{'loss': 0.0039, 'learning_rate': 1.3450003671949707e-05, 'epoch': 1.35}\n",
      "{'loss': 0.0022, 'learning_rate': 1.321063825285091e-05, 'epoch': 1.37}\n",
      "{'loss': 0.0031, 'learning_rate': 1.296920375328275e-05, 'epoch': 1.4}\n",
      "{'loss': 0.0035, 'learning_rate': 1.2725855764553981e-05, 'epoch': 1.42}\n",
      "{'loss': 0.0026, 'learning_rate': 1.248075111111229e-05, 'epoch': 1.44}\n",
      "{'loss': 0.0033, 'learning_rate': 1.2234047749479543e-05, 'epoch': 1.46}\n",
      "{'loss': 0.0027, 'learning_rate': 1.1985904666457455e-05, 'epoch': 1.48}\n",
      "{'loss': 0.0026, 'learning_rate': 1.1736481776669307e-05, 'epoch': 1.5}\n",
      "{'loss': 0.0055, 'learning_rate': 1.1485939819503717e-05, 'epoch': 1.53}\n",
      "{'loss': 0.0023, 'learning_rate': 1.1234440255526948e-05, 'epoch': 1.55}\n",
      "{'loss': 0.0047, 'learning_rate': 1.0982145162430373e-05, 'epoch': 1.57}\n",
      "{'loss': 0.0054, 'learning_rate': 1.0729217130580309e-05, 'epoch': 1.59}\n",
      "{'loss': 0.0043, 'learning_rate': 1.0475819158237426e-05, 'epoch': 1.61}\n",
      "{'loss': 0.0048, 'learning_rate': 1.0222114546513296e-05, 'epoch': 1.64}\n",
      "{'loss': 0.0024, 'learning_rate': 9.968266794131778e-06, 'epoch': 1.66}\n",
      "{'loss': 0.0034, 'learning_rate': 9.71443949206304e-06, 'epoch': 1.68}\n",
      "{'loss': 0.0036, 'learning_rate': 9.460796218098143e-06, 'epoch': 1.7}\n",
      "{'loss': 0.0038, 'learning_rate': 9.207500431432115e-06, 'epoch': 1.72}\n",
      "{'loss': 0.0032, 'learning_rate': 8.954715367323468e-06, 'epoch': 1.74}\n",
      "{'loss': 0.0134, 'learning_rate': 8.702603931897983e-06, 'epoch': 1.77}\n",
      "{'loss': 0.0022, 'learning_rate': 8.451328597164679e-06, 'epoch': 1.79}\n",
      "{'loss': 0.0067, 'learning_rate': 8.201051296311462e-06, 'epoch': 1.81}\n",
      "{'loss': 0.0023, 'learning_rate': 7.951933319348095e-06, 'epoch': 1.83}\n",
      "{'loss': 0.0073, 'learning_rate': 7.704135209163589e-06, 'epoch': 1.85}\n",
      "{'loss': 0.0018, 'learning_rate': 7.4578166580651335e-06, 'epoch': 1.88}\n",
      "{'loss': 0.0015, 'learning_rate': 7.213136404865124e-06, 'epoch': 1.9}\n",
      "{'loss': 0.0041, 'learning_rate': 6.970252132582729e-06, 'epoch': 1.92}\n",
      "{'loss': 0.0022, 'learning_rate': 6.729320366825785e-06, 'epoch': 1.94}\n",
      "{'loss': 0.0035, 'learning_rate': 6.490496374918647e-06, 'epoch': 1.96}\n",
      "{'loss': 0.004, 'learning_rate': 6.25393406584088e-06, 'epoch': 1.98}\n",
      "{'loss': 0.0036, 'learning_rate': 6.019785891041381e-06, 'epoch': 2.01}\n",
      "{'loss': 0.0011, 'learning_rate': 5.788202746191735e-06, 'epoch': 2.03}\n",
      "{'loss': 0.0022, 'learning_rate': 5.559333873942259e-06, 'epoch': 2.05}\n",
      "{'loss': 0.0025, 'learning_rate': 5.333326767743263e-06, 'epoch': 2.07}\n",
      "{'loss': 0.0026, 'learning_rate': 5.110327076793613e-06, 'epoch': 2.09}\n",
      "{'loss': 0.0027, 'learning_rate': 4.890478512177796e-06, 'epoch': 2.12}\n",
      "{'loss': 0.0036, 'learning_rate': 4.673922754252001e-06, 'epoch': 2.14}\n",
      "{'loss': 0.003, 'learning_rate': 4.460799361338898e-06, 'epoch': 2.16}\n",
      "{'loss': 0.0044, 'learning_rate': 4.251245679789928e-06, 'epoch': 2.18}\n",
      "{'loss': 0.0007, 'learning_rate': 4.045396755473121e-06, 'epoch': 2.2}\n",
      "{'loss': 0.0038, 'learning_rate': 3.8433852467434175e-06, 'epoch': 2.22}\n",
      "{'loss': 0.0022, 'learning_rate': 3.645341338951639e-06, 'epoch': 2.25}\n",
      "{'loss': 0.0012, 'learning_rate': 3.4513926605471504e-06, 'epoch': 2.27}\n",
      "{'loss': 0.0018, 'learning_rate': 3.2616642008283218e-06, 'epoch': 2.29}\n",
      "{'loss': 0.0026, 'learning_rate': 3.076278229393773e-06, 'epoch': 2.31}\n",
      "{'loss': 0.0032, 'learning_rate': 2.8953542173463133e-06, 'epoch': 2.33}\n",
      "{'loss': 0.0026, 'learning_rate': 2.719008760300359e-06, 'epoch': 2.36}\n",
      "{'loss': 0.0031, 'learning_rate': 2.5473555032424534e-06, 'epoch': 2.38}\n",
      "{'loss': 0.0037, 'learning_rate': 2.380505067293293e-06, 'epoch': 2.4}\n",
      "{'loss': 0.0051, 'learning_rate': 2.218564978418475e-06, 'epoch': 2.42}\n",
      "{'loss': 0.0006, 'learning_rate': 2.0616395981339076e-06, 'epoch': 2.44}\n",
      "{'loss': 0.0016, 'learning_rate': 1.9098300562505266e-06, 'epoch': 2.46}\n",
      "{'loss': 0.0033, 'learning_rate': 1.7632341857016733e-06, 'epoch': 2.49}\n",
      "{'loss': 0.001, 'learning_rate': 1.6219464594951273e-06, 'epoch': 2.51}\n",
      "{'loss': 0.0025, 'learning_rate': 1.4860579298304311e-06, 'epoch': 2.53}\n",
      "{'loss': 0.002, 'learning_rate': 1.3556561694207337e-06, 'epoch': 2.55}\n",
      "{'loss': 0.0019, 'learning_rate': 1.230825215056971e-06, 'epoch': 2.57}\n",
      "{'loss': 0.0029, 'learning_rate': 1.1116455134507665e-06, 'epoch': 2.6}\n",
      "{'loss': 0.0016, 'learning_rate': 9.981938693909221e-07, 'epoch': 2.62}\n",
      "{'loss': 0.0012, 'learning_rate': 8.905433962469489e-07, 'epoch': 2.64}\n",
      "{'loss': 0.0075, 'learning_rate': 7.887634688515e-07, 'epoch': 2.66}\n",
      "{'loss': 0.0038, 'learning_rate': 6.9291967879209e-07, 'epoch': 2.68}\n",
      "{'loss': 0.0009, 'learning_rate': 6.030737921409169e-07, 'epoch': 2.7}\n",
      "{'loss': 0.0018, 'learning_rate': 5.192837096500058e-07, 'epoch': 2.73}\n",
      "{'loss': 0.0018, 'learning_rate': 4.4160342943734723e-07, 'epoch': 2.75}\n",
      "{'loss': 0.0013, 'learning_rate': 3.7008301218807716e-07, 'epoch': 2.77}\n",
      "{'loss': 0.0023, 'learning_rate': 3.0476854889308737e-07, 'epoch': 2.79}\n",
      "{'loss': 0.0034, 'learning_rate': 2.4570213114592957e-07, 'epoch': 2.81}\n",
      "{'loss': 0.0028, 'learning_rate': 1.9292182401707603e-07, 'epoch': 2.84}\n",
      "{'loss': 0.0036, 'learning_rate': 1.464616415230702e-07, 'epoch': 2.86}\n",
      "{'loss': 0.0032, 'learning_rate': 1.0635152470635513e-07, 'epoch': 2.88}\n",
      "{'loss': 0.0025, 'learning_rate': 7.261732233991514e-08, 'epoch': 2.9}\n",
      "{'loss': 0.0016, 'learning_rate': 4.528077426915412e-08, 'epoch': 2.92}\n",
      "{'loss': 0.0029, 'learning_rate': 2.4359497401758026e-08, 'epoch': 2.94}\n",
      "{'loss': 0.0009, 'learning_rate': 9.866974354560966e-09, 'epoch': 2.97}\n",
      "{'loss': 0.0034, 'learning_rate': 1.8125447647421302e-09, 'epoch': 2.99}\n",
      "{'train_runtime': 3556.0537, 'train_samples_per_second': 6.186, 'train_steps_per_second': 0.774, 'train_loss': 0.04437256334346128, 'epoch': 3.0}\n",
      "CPU times: user 34min 59s, sys: 24min 16s, total: 59min 16s\n",
      "Wall time: 59min 16s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2751, training_loss=0.04437256334346128, metrics={'train_runtime': 3556.0537, 'train_samples_per_second': 6.186, 'train_steps_per_second': 0.774, 'train_loss': 0.04437256334346128, 'epoch': 3.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/kd/Documents/pii_detection/models//deberta_large/tokenizer_config.json',\n",
       " '/home/kd/Documents/pii_detection/models//deberta_large/special_tokens_map.json',\n",
       " '/home/kd/Documents/pii_detection/models//deberta_large/spm.model',\n",
       " '/home/kd/Documents/pii_detection/models//deberta_large/added_tokens.json',\n",
       " '/home/kd/Documents/pii_detection/models//deberta_large/tokenizer.json')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(OUTPUT_DIR + \"/deberta_large\")\n",
    "tokenizer.save_pretrained(OUTPUT_DIR + \"/deberta_large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
